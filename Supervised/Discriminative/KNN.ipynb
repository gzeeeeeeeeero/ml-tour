{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c081fa-445d-45e2-8e2e-a23dcc4dd285",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours - Regrs & Clasf Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011f243-8076-4db9-8988-0d0fe468e7ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Nearest Neighbours\n",
    "\n",
    "In **Nearest Neighbours** we're given a training dataset $\\Psi = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})\\}$\n",
    "where $x$ are some features and $y$ is the class they belong to and we would like to predict the class of some unseen input $x'$.\n",
    "We do that by simply finding which example in $\\Psi$ is \"closest\" to $x'$ and choose the label of that to be label of $x'$. Distance is usually measured in *Euclidean* metric.\n",
    "\n",
    "However this approach gives very undesirable results sometimes\n",
    "for eg:\n",
    "\n",
    "<img src=\"ast/1.png\" width=450px height = 225px>\n",
    "\n",
    "*Outliers* can mess up predictions !\n",
    "\n",
    "### K Nearest Neighbours\n",
    "\n",
    "A better way to Implement this algorithm is to look at **$K$ Nearest Neighbours** (or a neighbourhood) of $x'$ i.e. $\\Phi \\subseteq \\Psi = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(K)}, y^{(K)})\\}$ and thus $y'$ can be the *mode* of that neighbourhood, in **Regression** we look at the *average* instead.\n",
    " \n",
    " This gives more smoother predictions:\n",
    "\n",
    "<img src=\"ast/2.png\" width=450px height = 225px>\n",
    "\n",
    "Both for classification and regression, a useful technique can be to assign weights to the contributions of the neighbors, so that the nearer neighbors contribute more to the average than the more distant ones. For example, a common weighting scheme consists in giving each neighbor a weight of 1/d, where d is the distance to the neighbor.\n",
    "\n",
    "\n",
    "Pending : CNN (Condensed Nearest Neighbour)\n",
    "\n",
    "---\n",
    "\n",
    "Further Reading : \n",
    "- [Large Margin Nearest Neighbor](https://en.wikipedia.org/wiki/Large_Margin_Nearest_Neighbor)\n",
    "- [Neighbourhood components analysis](https://en.wikipedia.org/wiki/Neighbourhood_components_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
